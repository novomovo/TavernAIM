{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOch3RKsWcDWGq75hKfuVHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TavernAI/TavernAI/blob/main/colab/API-ONLY_for_node.js_local-TavernAI_v0.98RC.ipynb\" target=\"_parent\"><img src=\"https://www.tavernai.xyz/oic.png\" alt=\"Open In Colab\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title { run: \"auto\", form-width: \"110%\", display-mode: \"form\" }\n",
        "#@markdown\n",
        "%%html --isolated\n",
        "<audio autoplay=\"\" loop src=\"https://tavernai.xyz/silence.m4a\"></audio><video autoplay=\"\" src=\"https://tavernai.xyz/NFM.Colab.WAIT.mp4\" controls></video><br><h1><b>Now...&nbsp&nbsp&nbspWAIT...&nbsp&nbsp&nbsp&nbsp--FunkEngine</b></h1>"
      ],
      "metadata": {
        "id": "LG58x0USTVOA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select a model from, or paste your desired model **into** the menu.\n",
        "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n",
        "# --RUN THE CELL--\n",
        "# ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓"
      ],
      "metadata": {
        "id": "CHfRyPxyDuND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <b>KoboldAI</b> { form-width: \"110%\", display-mode: \"form\" }\n",
        "SECRET_TUNNEL = False # @param {type:\"boolean\"}\n",
        "Model = \"NeverSleep/Noromaid-13b-v0.1.1\" # @param [\"NeverSleep/Noromaid-13b-v0.1.1\", \"NeverSleep/Nethena-13B\", \"Xwin-LM/Xwin-LM-13B-V0.2\", \"WizardLM/WizardLM-13B-V1.2\", \"baichuan-inc/Baichuan2-13B-Chat\", \"Undi95/MLewd-v2.4-13B\", \"codellama/CodeLlama-13b-Python-hf\", \"codellama/CodeLlama-13b-hf\", \"WizardLM/WizardCoder-15B-V1.0\", \"WizardLM/WizardCoder-Python-13B-V1.0\", \"Xwin-LM/XwinCoder-13B\", \"Xwin-LM/Xwin-Math-13B-V1.0\", \"WizardLM/WizardMath-13B-V1.0\", \"FunkEngine/SchweinZwei-13b\", \"FunkEngine/FunkEngine-6B\", \"Xwin-LM/Xwin-LM-7B-V0.1\", \"Undi95/Nete-13B\", \"KoboldAI/OPT-13B-Erebus\", \"####↓↓WHY↓↓DO↓↓YOU↓↓USE↓↓THESE?####\", \"KoboldAI/OPT-6B-nerys-v2\", \"KoboldAI/OPT-6.7B-Erebus\", \"KoboldAI/OPT-6.7B-Nerybus-Mix\", \"####2019↓↓CALLED↓↓THEY↓↓WANT↓↓THEIR↓↓MODELS↓↓BACK####\", \"KoboldAI/OPT-2.7B-Erebus\"] {allow-input: true}\n",
        "\n",
        "# FunkEngine's implementation©\n",
        "\n",
        "# KoboldAI mostly by Henky!!©\n",
        "\n",
        "import os\n",
        "os.chdir('/')\n",
        "!!rm -rf /content/sample_data/\n",
        "!!nvidia-smi -pm 1\n",
        "!!nvidia-smi -pl 69\n",
        "!!nvidia-smi -c 3\n",
        "os.chdir('/content/')\n",
        "\n",
        "if SECRET_TUNNEL:\n",
        "    from google.colab import userdata\n",
        "    print(\"Do you have static tunnel infrastructure ready to use?\")\n",
        "    kobotoke = userdata.get('COLABKOBOLDSEC')\n",
        "    if kobotoke  != '':\n",
        "        print(\"It would seem you are on the upper end of the bell-curve...\")\n",
        "        !!wget https://github.com/cloudflare/cloudflared/releases/download/2023.10.0/cloudflared-linux-amd64.deb\n",
        "        print(\"Using provided token hashes to plumb into your tunnel infrastructure.\")\n",
        "        !!sudo dpkg -i cloudflared-linux-amd64.deb\n",
        "        print(\"Cloudflared installed properly, ready to deploy!\")\n",
        "        if kobotoke != '':\n",
        "            print(\"Looks like you have given us a token for tunneling KoboldAI's API out...\")\n",
        "            !!nohup cloudflared tunnel --no-autoupdate run --token $kobotoke &\n",
        "            print(\"Connector is up and running... For KoboldAI...\")\n",
        "    print(\"Tunnels plumbed in should be good to go now...\")\n",
        "else:\n",
        "    print(\"So you like copying and pasting new links every time... YDY I guess..  --FunkEngine\")\n",
        "\n",
        "if not os.path.exists(\"/content/KoboldAI\"):\n",
        "    !nvidia-smi\n",
        "    !!sudo nohup pip install typing >/dev/null\n",
        "    !!sudo nohup pip install --ignore-installed blinker==1.6.2\n",
        "    os.mkdir(\"/content/KoboldAI\")\n",
        "    !!git clone -b united https://github.com/henk717/KoboldAI /content/KoboldAI/\n",
        "    os.chdir('/content/KoboldAI')\n",
        "    !!git submodule update --init --recursive\n",
        "    !!pip install -r requirements.txt\n",
        "    !nvidia-smi\n",
        "\n",
        "if os.path.exists(\"/content/KoboldAI/\"):\n",
        "    os.chdir('/content/KoboldAI/')\n",
        "    if SECRET_TUNNEL:\n",
        "        print(\"REMINDER: YOU ARE USING YOUR PROVIDED TUNNEL CONNECTOR HERE. KoboldAI WILL NOT GIVE YOU AN API LINK. YOU ALREADY HAVE IT.\")\n",
        "        !!python3 aiserver.py --cacheonly --quiet --model $Model\n",
        "    if not SECRET_TUNNEL:\n",
        "        print(\"Lauunching KoboldAI and asking it to give you a regular old 'copy-and-paste-style' randomized-words API tunnel...\")\n",
        "        print(\"You must enjoy copying and pasting the links every time.\")\n",
        "        !!python3 aiserver.py --remote --cacheonly --quiet --model $Model\n",
        "\n",
        "print(\"Something has clearly gone terribly wrong if this appears in the output panel...\")\n"
      ],
      "metadata": {
        "id": "3OpDMFC5RFpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
